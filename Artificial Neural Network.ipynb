{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Following Neural network is implemented using keras, Tensorflow as backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = loadmat('ex3data1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "y_t = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_labels = 10\n",
    "y = np.zeros([y_t.shape[0], num_labels])\n",
    "for i in range(0, y_t.shape[0]):\n",
    "    if y_t[i] == 10:\n",
    "        y_t[i] = 0\n",
    "    y[i, y_t[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are designing our neural netwok. Here we Dont care about accuracy, simple make the madel with our intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=25, input_shape=(400,), kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "classifier.add(Dropout(rate=.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=10, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "classifier.add(Dropout(rate=.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 1s 271us/step - loss: 0.5603 - acc: 0.8338\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 1s 100us/step - loss: 0.4523 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 0s 70us/step - loss: 0.4096 - acc: 0.9005\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 0s 70us/step - loss: 0.3744 - acc: 0.9036\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 0s 71us/step - loss: 0.3603 - acc: 0.9121\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 0s 96us/step - loss: 0.3359 - acc: 0.9252\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 0s 83us/step - loss: 0.3249 - acc: 0.9354\n",
      "Epoch 8/50\n",
      "5000/5000 [==============================] - 0s 72us/step - loss: 0.2898 - acc: 0.9454\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 0s 72us/step - loss: 0.2816 - acc: 0.9513\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 0s 71us/step - loss: 0.2786 - acc: 0.9550\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 0s 73us/step - loss: 0.2587 - acc: 0.9594\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 0s 73us/step - loss: 0.2571 - acc: 0.9621\n",
      "Epoch 13/50\n",
      "5000/5000 [==============================] - 0s 72us/step - loss: 0.2442 - acc: 0.9643\n",
      "Epoch 14/50\n",
      "5000/5000 [==============================] - 0s 72us/step - loss: 0.2532 - acc: 0.9653\n",
      "Epoch 15/50\n",
      "5000/5000 [==============================] - 0s 74us/step - loss: 0.2471 - acc: 0.9665\n",
      "Epoch 16/50\n",
      "5000/5000 [==============================] - 0s 72us/step - loss: 0.2433 - acc: 0.9673\n",
      "Epoch 17/50\n",
      "5000/5000 [==============================] - 0s 72us/step - loss: 0.2391 - acc: 0.9683\n",
      "Epoch 18/50\n",
      "5000/5000 [==============================] - 0s 71us/step - loss: 0.2399 - acc: 0.9694\n",
      "Epoch 19/50\n",
      "5000/5000 [==============================] - 0s 71us/step - loss: 0.2288 - acc: 0.9708\n",
      "Epoch 20/50\n",
      "5000/5000 [==============================] - 0s 72us/step - loss: 0.2361 - acc: 0.9682\n",
      "Epoch 21/50\n",
      "5000/5000 [==============================] - 0s 76us/step - loss: 0.2279 - acc: 0.9695\n",
      "Epoch 22/50\n",
      "5000/5000 [==============================] - 0s 76us/step - loss: 0.2180 - acc: 0.9708\n",
      "Epoch 23/50\n",
      "5000/5000 [==============================] - 0s 81us/step - loss: 0.2259 - acc: 0.9706\n",
      "Epoch 24/50\n",
      "5000/5000 [==============================] - 1s 104us/step - loss: 0.2080 - acc: 0.9719\n",
      "Epoch 25/50\n",
      "5000/5000 [==============================] - 0s 92us/step - loss: 0.2218 - acc: 0.9713\n",
      "Epoch 26/50\n",
      "5000/5000 [==============================] - 0s 89us/step - loss: 0.2295 - acc: 0.9720\n",
      "Epoch 27/50\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 0.2216 - acc: 0.9715\n",
      "Epoch 28/50\n",
      "5000/5000 [==============================] - 0s 71us/step - loss: 0.2170 - acc: 0.9725\n",
      "Epoch 29/50\n",
      "5000/5000 [==============================] - 0s 74us/step - loss: 0.2232 - acc: 0.9719\n",
      "Epoch 30/50\n",
      "5000/5000 [==============================] - 0s 74us/step - loss: 0.2157 - acc: 0.9726\n",
      "Epoch 31/50\n",
      "5000/5000 [==============================] - 0s 70us/step - loss: 0.2163 - acc: 0.9731\n",
      "Epoch 32/50\n",
      "5000/5000 [==============================] - 0s 73us/step - loss: 0.2198 - acc: 0.9731\n",
      "Epoch 33/50\n",
      "5000/5000 [==============================] - 0s 74us/step - loss: 0.2162 - acc: 0.9728\n",
      "Epoch 34/50\n",
      "5000/5000 [==============================] - 0s 76us/step - loss: 0.2190 - acc: 0.9728\n",
      "Epoch 35/50\n",
      "5000/5000 [==============================] - 0s 76us/step - loss: 0.2097 - acc: 0.9738\n",
      "Epoch 36/50\n",
      "5000/5000 [==============================] - 0s 90us/step - loss: 0.1987 - acc: 0.9737\n",
      "Epoch 37/50\n",
      "5000/5000 [==============================] - 0s 82us/step - loss: 0.2270 - acc: 0.9727\n",
      "Epoch 38/50\n",
      "5000/5000 [==============================] - 1s 100us/step - loss: 0.1997 - acc: 0.9747\n",
      "Epoch 39/50\n",
      "5000/5000 [==============================] - 1s 102us/step - loss: 0.1981 - acc: 0.9747\n",
      "Epoch 40/50\n",
      "5000/5000 [==============================] - 0s 83us/step - loss: 0.2205 - acc: 0.9740\n",
      "Epoch 41/50\n",
      "5000/5000 [==============================] - 0s 94us/step - loss: 0.2064 - acc: 0.9745\n",
      "Epoch 42/50\n",
      "5000/5000 [==============================] - 0s 96us/step - loss: 0.2039 - acc: 0.9748\n",
      "Epoch 43/50\n",
      "5000/5000 [==============================] - 0s 74us/step - loss: 0.2081 - acc: 0.9750\n",
      "Epoch 44/50\n",
      "5000/5000 [==============================] - 0s 73us/step - loss: 0.2017 - acc: 0.9749\n",
      "Epoch 45/50\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.2057 - acc: 0.9747\n",
      "Epoch 46/50\n",
      "5000/5000 [==============================] - 0s 80us/step - loss: 0.2150 - acc: 0.9744\n",
      "Epoch 47/50\n",
      "5000/5000 [==============================] - 0s 78us/step - loss: 0.2129 - acc: 0.9750\n",
      "Epoch 48/50\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 0.2094 - acc: 0.9749\n",
      "Epoch 49/50\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 0.2116 - acc: 0.9751\n",
      "Epoch 50/50\n",
      "5000/5000 [==============================] - 0s 73us/step - loss: 0.2069 - acc: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2f6efbc50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x=X, y=y, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=25, input_shape=(400,), kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    classifier.add(Dense(units=10, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 132us/step - loss: 0.4212 - acc: 0.8598\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.2816 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.2470 - acc: 0.9001\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.2188 - acc: 0.9038\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.1934 - acc: 0.9186\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.1710 - acc: 0.9314\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.1530 - acc: 0.9434\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.1383 - acc: 0.9537\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.1262 - acc: 0.9602\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.1160 - acc: 0.9653\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.1074 - acc: 0.9699\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.1000 - acc: 0.9728\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0937 - acc: 0.9745\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0883 - acc: 0.9764\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0835 - acc: 0.9778\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0793 - acc: 0.9790\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0755 - acc: 0.9800\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0721 - acc: 0.9810\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0691 - acc: 0.9814\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0665 - acc: 0.9821\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0642 - acc: 0.9825\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0619 - acc: 0.9831\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0599 - acc: 0.9837\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0581 - acc: 0.9837\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0565 - acc: 0.9843\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0548 - acc: 0.9846\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0535 - acc: 0.9850\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0520 - acc: 0.9853\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0507 - acc: 0.9855\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0496 - acc: 0.9858\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0484 - acc: 0.9864\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0473 - acc: 0.9864\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0462 - acc: 0.9868\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0454 - acc: 0.9870\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 1s 146us/step - loss: 0.0444 - acc: 0.9872\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0436 - acc: 0.9874\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0426 - acc: 0.9877\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0419 - acc: 0.9878\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0410 - acc: 0.9881\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0402 - acc: 0.9885\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0395 - acc: 0.9888\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0388 - acc: 0.9889\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0381 - acc: 0.9890\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0374 - acc: 0.9893\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0369 - acc: 0.9895\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0362 - acc: 0.9899\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0356 - acc: 0.9899\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0351 - acc: 0.9900\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0344 - acc: 0.9903\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0339 - acc: 0.9903\n",
      "500/500 [==============================] - 0s 85us/step\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 145us/step - loss: 0.4158 - acc: 0.8623\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.2880 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.2500 - acc: 0.9000\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.2150 - acc: 0.9032\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.1866 - acc: 0.9210\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.1643 - acc: 0.9375\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.1466 - acc: 0.9480\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.1325 - acc: 0.9570\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.1208 - acc: 0.9635\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.1110 - acc: 0.9686\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.1027 - acc: 0.9723\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0957 - acc: 0.9748\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0896 - acc: 0.9765\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0843 - acc: 0.9784\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0798 - acc: 0.9796\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0758 - acc: 0.9806\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0722 - acc: 0.9814\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0690 - acc: 0.9820\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0662 - acc: 0.9827\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0635 - acc: 0.9829\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0613 - acc: 0.9838\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 81us/step - loss: 0.0591 - acc: 0.9841\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0572 - acc: 0.9846\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0553 - acc: 0.9851\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.0537 - acc: 0.9857\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.0521 - acc: 0.9858\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0506 - acc: 0.9862\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 86us/step - loss: 0.0492 - acc: 0.9870\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 103us/step - loss: 0.0479 - acc: 0.9868\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 1s 117us/step - loss: 0.0467 - acc: 0.9875\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 97us/step - loss: 0.0456 - acc: 0.9876\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 91us/step - loss: 0.0445 - acc: 0.9877\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 1s 131us/step - loss: 0.0435 - acc: 0.9880\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.0425 - acc: 0.9883\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0416 - acc: 0.9887\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0407 - acc: 0.9889\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0399 - acc: 0.9891\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0391 - acc: 0.9893\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0383 - acc: 0.9894\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0375 - acc: 0.9895\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0368 - acc: 0.9898\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0362 - acc: 0.9901\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0354 - acc: 0.9902\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0348 - acc: 0.9903\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0342 - acc: 0.9905\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0336 - acc: 0.9907\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0329 - acc: 0.9909\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0325 - acc: 0.9907\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0319 - acc: 0.9912\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0314 - acc: 0.9914\n",
      "500/500 [==============================] - 0s 117us/step\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 150us/step - loss: 0.4328 - acc: 0.8384\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.2946 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.2542 - acc: 0.9000\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.2215 - acc: 0.9044\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.1953 - acc: 0.9159\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.1729 - acc: 0.9320\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.1538 - acc: 0.9436\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.1377 - acc: 0.9545\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.1243 - acc: 0.9631\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.1127 - acc: 0.9688\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.1031 - acc: 0.9727\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0950 - acc: 0.9756\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0880 - acc: 0.9778\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0820 - acc: 0.9796\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0769 - acc: 0.9808\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0725 - acc: 0.9817\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0688 - acc: 0.9827\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0653 - acc: 0.9832\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0623 - acc: 0.9842\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0596 - acc: 0.9846\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0572 - acc: 0.9852\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0550 - acc: 0.9856\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0530 - acc: 0.9862\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0512 - acc: 0.9866\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0494 - acc: 0.9872\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0479 - acc: 0.9876\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0464 - acc: 0.9878\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0450 - acc: 0.9880\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0438 - acc: 0.9881\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0426 - acc: 0.9887\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0414 - acc: 0.9887\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0404 - acc: 0.9888\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0394 - acc: 0.9893\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0385 - acc: 0.9893\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0376 - acc: 0.9898\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 86us/step - loss: 0.0367 - acc: 0.9900\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.0359 - acc: 0.9901\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0351 - acc: 0.9903\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0344 - acc: 0.9909\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0337 - acc: 0.9907\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0331 - acc: 0.9911\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0323 - acc: 0.9913\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0317 - acc: 0.9914\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0311 - acc: 0.9915\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0305 - acc: 0.9918\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0299 - acc: 0.9918\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0294 - acc: 0.9922\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0289 - acc: 0.9922\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0284 - acc: 0.9923\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0279 - acc: 0.9926\n",
      "500/500 [==============================] - 0s 154us/step\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 177us/step - loss: 0.4764 - acc: 0.8053\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.2966 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.2630 - acc: 0.9000\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.2323 - acc: 0.9036\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.2069 - acc: 0.9115\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.1850 - acc: 0.9221\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.1652 - acc: 0.9346\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.1481 - acc: 0.9441\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.1337 - acc: 0.9535\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.1217 - acc: 0.9615\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.1114 - acc: 0.9676\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.1027 - acc: 0.9716\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0954 - acc: 0.9746\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0889 - acc: 0.9768\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0834 - acc: 0.9786\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0785 - acc: 0.9798\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0742 - acc: 0.9816\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0704 - acc: 0.9822\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0670 - acc: 0.9828\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0639 - acc: 0.9837\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0611 - acc: 0.9844\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0586 - acc: 0.9850\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0563 - acc: 0.9853\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0543 - acc: 0.9860\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0523 - acc: 0.9863\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0505 - acc: 0.9868\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0488 - acc: 0.9870\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0474 - acc: 0.9875\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0460 - acc: 0.9877\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0446 - acc: 0.9880\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0433 - acc: 0.9882\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0421 - acc: 0.9887\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0410 - acc: 0.9888\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0400 - acc: 0.9891\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0389 - acc: 0.9895\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0379 - acc: 0.9897\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0371 - acc: 0.9899\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0362 - acc: 0.9900\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0353 - acc: 0.9902\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0345 - acc: 0.9906\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0338 - acc: 0.9907\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0331 - acc: 0.9910\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0323 - acc: 0.9912\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0317 - acc: 0.9914\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0310 - acc: 0.9914\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0304 - acc: 0.9917\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0298 - acc: 0.9920\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0293 - acc: 0.9919\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0287 - acc: 0.9920\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0281 - acc: 0.9925\n",
      "500/500 [==============================] - 0s 185us/step\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 183us/step - loss: 0.4671 - acc: 0.8095\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.3012 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 89us/step - loss: 0.2659 - acc: 0.9000\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.2393 - acc: 0.9001: 0s - loss: 0.2503 - acc:\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.2121 - acc: 0.9053\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.1884 - acc: 0.9193\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.1675 - acc: 0.9340\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.1499 - acc: 0.945 - 0s 79us/step - loss: 0.1491 - acc: 0.9464\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 89us/step - loss: 0.1332 - acc: 0.9568\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 86us/step - loss: 0.1202 - acc: 0.9648\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 95us/step - loss: 0.1094 - acc: 0.9698\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.1005 - acc: 0.9729\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0931 - acc: 0.9753\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0869 - acc: 0.9773\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0816 - acc: 0.9791\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0770 - acc: 0.9802\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0731 - acc: 0.9809\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0696 - acc: 0.9822\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0665 - acc: 0.9828\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0637 - acc: 0.9835\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0613 - acc: 0.9842\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0590 - acc: 0.9846\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0569 - acc: 0.9852\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0550 - acc: 0.9855\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0533 - acc: 0.9861\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.0517 - acc: 0.9864\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 99us/step - loss: 0.0502 - acc: 0.9867\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 1s 138us/step - loss: 0.0488 - acc: 0.9872\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 111us/step - loss: 0.0476 - acc: 0.9873\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 96us/step - loss: 0.0463 - acc: 0.9876\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0452 - acc: 0.9879\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.0441 - acc: 0.9881\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0431 - acc: 0.9887\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0421 - acc: 0.9886\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0412 - acc: 0.9889\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0404 - acc: 0.9891\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0395 - acc: 0.9893\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0387 - acc: 0.9894\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0380 - acc: 0.9898\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0372 - acc: 0.9898\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.0365 - acc: 0.9901\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0358 - acc: 0.9902\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0351 - acc: 0.9904\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 86us/step - loss: 0.0345 - acc: 0.9906\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 103us/step - loss: 0.0337 - acc: 0.9910\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 96us/step - loss: 0.0332 - acc: 0.9909\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 81us/step - loss: 0.0327 - acc: 0.9910\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0322 - acc: 0.9911\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 93us/step - loss: 0.0315 - acc: 0.9914\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 93us/step - loss: 0.0310 - acc: 0.9914\n",
      "500/500 [==============================] - 0s 284us/step\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 246us/step - loss: 0.4017 - acc: 0.8670\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.2706 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.2257 - acc: 0.9013\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.1948 - acc: 0.9121\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.1712 - acc: 0.9280\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.1513 - acc: 0.9439\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.1346 - acc: 0.9552\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.1210 - acc: 0.9637\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.1098 - acc: 0.9701\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.1003 - acc: 0.9744\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0922 - acc: 0.9775\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0854 - acc: 0.9800\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0795 - acc: 0.9816\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0745 - acc: 0.9827\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0700 - acc: 0.9838\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0662 - acc: 0.9845\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0628 - acc: 0.9852\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0598 - acc: 0.9859\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0571 - acc: 0.9864\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0547 - acc: 0.9867\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0526 - acc: 0.9872\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0506 - acc: 0.9879\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0488 - acc: 0.9880\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0472 - acc: 0.9882\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0456 - acc: 0.9888\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0442 - acc: 0.9891\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0430 - acc: 0.9893\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0418 - acc: 0.9894\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0407 - acc: 0.9897\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0396 - acc: 0.9900\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.0386 - acc: 0.9899\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0377 - acc: 0.9905\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0367 - acc: 0.9905\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0360 - acc: 0.9908\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0351 - acc: 0.9907\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.0343 - acc: 0.9911\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.0337 - acc: 0.9911\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0328 - acc: 0.9913\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0322 - acc: 0.9915\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0315 - acc: 0.9916\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 81us/step - loss: 0.0309 - acc: 0.9918\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 82us/step - loss: 0.0303 - acc: 0.9920\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 82us/step - loss: 0.0298 - acc: 0.9920\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0291 - acc: 0.9922\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0287 - acc: 0.9924\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0281 - acc: 0.9927\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0276 - acc: 0.9926\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0270 - acc: 0.9930\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0266 - acc: 0.9931\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0262 - acc: 0.9931\n",
      "500/500 [==============================] - 0s 234us/step\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 249us/step - loss: 0.3976 - acc: 0.8692\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.2792 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.2421 - acc: 0.9002\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.2145 - acc: 0.9046\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 96us/step - loss: 0.1914 - acc: 0.9192\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 90us/step - loss: 0.1711 - acc: 0.9311\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 86us/step - loss: 0.1541 - acc: 0.9418\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 91us/step - loss: 0.1397 - acc: 0.9510\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 90us/step - loss: 0.1274 - acc: 0.9578\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 91us/step - loss: 0.1169 - acc: 0.9642\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.1080 - acc: 0.9691\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 91us/step - loss: 0.1005 - acc: 0.9721\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 86us/step - loss: 0.0940 - acc: 0.9745\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 91us/step - loss: 0.0883 - acc: 0.9766\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.0834 - acc: 0.9783\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.0791 - acc: 0.9795\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0753 - acc: 0.9805\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0719 - acc: 0.9812\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0688 - acc: 0.9819\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0661 - acc: 0.9827\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0637 - acc: 0.9833\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0614 - acc: 0.9834\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0594 - acc: 0.9842\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0575 - acc: 0.9843\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0559 - acc: 0.9850\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0542 - acc: 0.9855\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0528 - acc: 0.9856\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0514 - acc: 0.9861\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0501 - acc: 0.9864\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0489 - acc: 0.9865\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0477 - acc: 0.9868\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0466 - acc: 0.9872\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0456 - acc: 0.9876\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0445 - acc: 0.9876\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0437 - acc: 0.9879\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0427 - acc: 0.9883\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0419 - acc: 0.9884\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0410 - acc: 0.9889\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0402 - acc: 0.9888\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0394 - acc: 0.9891\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0387 - acc: 0.9894\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0379 - acc: 0.9894\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0371 - acc: 0.9897\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0366 - acc: 0.9896\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0359 - acc: 0.9901\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0353 - acc: 0.9901\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0346 - acc: 0.9904\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0342 - acc: 0.9905\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0335 - acc: 0.9906\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0329 - acc: 0.9910\n",
      "500/500 [==============================] - 0s 239us/step\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 185us/step - loss: 0.3641 - acc: 0.8817\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.2754 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.2346 - acc: 0.9033\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.2005 - acc: 0.9131\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.1735 - acc: 0.9295\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.1519 - acc: 0.9420\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.1346 - acc: 0.9547\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.1207 - acc: 0.9639\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.1093 - acc: 0.9702\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0998 - acc: 0.9738\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0919 - acc: 0.9767\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0852 - acc: 0.9785\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0796 - acc: 0.9799\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0748 - acc: 0.9809\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0705 - acc: 0.9818\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0669 - acc: 0.9830\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0636 - acc: 0.9836\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0608 - acc: 0.9841\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0583 - acc: 0.9849\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0560 - acc: 0.9855\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0539 - acc: 0.9857\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0520 - acc: 0.9860\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0504 - acc: 0.9863\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0487 - acc: 0.9868\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0473 - acc: 0.9871\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0459 - acc: 0.9876\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0446 - acc: 0.9879\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0434 - acc: 0.9880\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0423 - acc: 0.9882\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0412 - acc: 0.9885\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0402 - acc: 0.9890\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0392 - acc: 0.9891\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0384 - acc: 0.9894\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0375 - acc: 0.9899\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0368 - acc: 0.9899\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0360 - acc: 0.9903\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0352 - acc: 0.9904\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.0345 - acc: 0.9906\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0338 - acc: 0.9906\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0332 - acc: 0.9909\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0325 - acc: 0.9910\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0319 - acc: 0.9910\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0313 - acc: 0.9911\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0308 - acc: 0.9914\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0302 - acc: 0.9916\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0296 - acc: 0.9917\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0291 - acc: 0.9920\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 82us/step - loss: 0.0287 - acc: 0.9920\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0281 - acc: 0.9922\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0277 - acc: 0.9923\n",
      "500/500 [==============================] - 0s 260us/step\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 181us/step - loss: 0.3952 - acc: 0.8644\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.2794 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.2406 - acc: 0.9001\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.2066 - acc: 0.9105\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.1791 - acc: 0.9254\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.1570 - acc: 0.9375\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.1391 - acc: 0.9534\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.1244 - acc: 0.9633\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.1124 - acc: 0.9691\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.1023 - acc: 0.9731\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0941 - acc: 0.9764\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0870 - acc: 0.9785\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0808 - acc: 0.9801\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0757 - acc: 0.9814\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0712 - acc: 0.9822\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0672 - acc: 0.9832\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0637 - acc: 0.9839\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0606 - acc: 0.9846\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0579 - acc: 0.9852\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0554 - acc: 0.9855\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0532 - acc: 0.9860\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0512 - acc: 0.9866\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0494 - acc: 0.9870\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0477 - acc: 0.9873\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0461 - acc: 0.9881\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0445 - acc: 0.9884\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0433 - acc: 0.9886\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0419 - acc: 0.9892\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0408 - acc: 0.9893\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0396 - acc: 0.9897\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0386 - acc: 0.9900\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0376 - acc: 0.9900\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0367 - acc: 0.9903\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0358 - acc: 0.9905\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0349 - acc: 0.9907\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0342 - acc: 0.9908\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0333 - acc: 0.9911\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0327 - acc: 0.9910\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0319 - acc: 0.9916\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0313 - acc: 0.9915\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0306 - acc: 0.9918\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0301 - acc: 0.9919\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0295 - acc: 0.9921\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0288 - acc: 0.9922\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0284 - acc: 0.9924\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0277 - acc: 0.9927\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0272 - acc: 0.9924\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 82us/step - loss: 0.0268 - acc: 0.9928\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0263 - acc: 0.9930\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0258 - acc: 0.9932\n",
      "500/500 [==============================] - 0s 427us/step\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 248us/step - loss: 0.3386 - acc: 0.8977\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 95us/step - loss: 0.2569 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.2170 - acc: 0.9027\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 86us/step - loss: 0.1860 - acc: 0.9204\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.1608 - acc: 0.9414\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 95us/step - loss: 0.1410 - acc: 0.9544\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.1252 - acc: 0.9628\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.1124 - acc: 0.9688\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.1021 - acc: 0.9728\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 82us/step - loss: 0.0935 - acc: 0.9754\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.0862 - acc: 0.9776\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0802 - acc: 0.9798\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 82us/step - loss: 0.0750 - acc: 0.9808\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.0704 - acc: 0.9819\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 109us/step - loss: 0.0666 - acc: 0.9828\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 1s 126us/step - loss: 0.0631 - acc: 0.9834\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 1s 134us/step - loss: 0.0600 - acc: 0.9843\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 1s 128us/step - loss: 0.0573 - acc: 0.9848\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 1s 134us/step - loss: 0.0549 - acc: 0.9855\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 1s 136us/step - loss: 0.0526 - acc: 0.9861\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 1s 134us/step - loss: 0.0507 - acc: 0.9867\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 1s 137us/step - loss: 0.0489 - acc: 0.9868\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 1s 125us/step - loss: 0.0472 - acc: 0.9871\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 1s 151us/step - loss: 0.0457 - acc: 0.9876\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 1s 146us/step - loss: 0.0442 - acc: 0.9881 0s - loss: 0.0432 - \n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 1s 138us/step - loss: 0.0429 - acc: 0.9883\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 1s 120us/step - loss: 0.0417 - acc: 0.9885\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 1s 133us/step - loss: 0.0405 - acc: 0.9889\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 1s 138us/step - loss: 0.0394 - acc: 0.9891\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.0383 - acc: 0.9896\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 1s 143us/step - loss: 0.0374 - acc: 0.9899\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 89us/step - loss: 0.0364 - acc: 0.9899\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 1s 177us/step - loss: 0.0356 - acc: 0.9902\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0347 - acc: 0.9904\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0340 - acc: 0.9907\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 81us/step - loss: 0.0332 - acc: 0.9911\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0325 - acc: 0.9909\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.0317 - acc: 0.9914\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0312 - acc: 0.9913\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0304 - acc: 0.9916\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0298 - acc: 0.9920\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0292 - acc: 0.9918\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0286 - acc: 0.9922\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0281 - acc: 0.9922\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 86us/step - loss: 0.0275 - acc: 0.9924\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0270 - acc: 0.9925\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0266 - acc: 0.9928\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0261 - acc: 0.9929\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0255 - acc: 0.9931\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0251 - acc: 0.9930\n",
      "500/500 [==============================] - 0s 341us/step\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn=build_classifier, batch_size=32, epochs=50)\n",
    "accuracies = cross_val_score(estimator=classifier, X=X, y=y, cv=10, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will implement K-Fold cross validation, here we will use 10 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82480006,  0.82540004,  0.82520004,  0.82740006,  0.82900005,\n",
       "        0.82780005,  0.81780003,  0.81480007,  0.83960004,  0.82200004])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825380048943\n",
      "0.00637523128274\n"
     ]
    }
   ],
   "source": [
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(mean)\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network is low variance and low bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use parameter tuning to find the paramter for maximum accuracy. here we will try "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=25, input_shape=(400,), kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    classifier.add(Dense(units=10, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn=build_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter = {'batch_size': [10, 32], 'nb_epoch': [30, 50], 'optimizer': ['adam', 'rmsprop']}\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=parameter, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4500/4500 [==============================] - 1s 222us/step - loss: 0.2984 - acc: 0.8938\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f36ee58fc786>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 638\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[1;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[1;32m--> 108\u001b[1;33m                                                  **self._kwargs)\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "grid_search = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 32]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  96.22\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(0, X.shape[0]):\n",
    "    tmp = y_pred[i,:].argmax()\n",
    "    if y_t[i] == tmp:\n",
    "        count = count + 1\n",
    "print(\"Accuracy : \",(count*100/X.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
